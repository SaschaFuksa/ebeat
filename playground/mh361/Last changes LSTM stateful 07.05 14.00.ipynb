{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import wave\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "import glob\n",
    "import os\n",
    "import Paths\n",
    "from pydub import AudioSegment\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, MaxPooling2D, Dropout, Activation\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "directory = os.listdir(Paths.IN_DIRECTORY)\n",
    "array = []\n",
    "\n",
    "sequence_length = []\n",
    "for sample_name in directory:\n",
    "    if 'wav' in sample_name:\n",
    "        file_path = os.path.join(Paths.IN_DIRECTORY, sample_name)\n",
    "        song, sr = librosa.load(file_path)\n",
    "        sequence_length.append(len(song))\n",
    "        #print(len(song))\n",
    "        #song = AudioSegment.from_wav(file_path)\n",
    "        #samples = song.get_array_of_samples()\n",
    "        array.append(song)\n",
    "\n",
    "# Removing the last element using slicing\n",
    "lastElementIndex = len(array)-1\n",
    "in_array = array[:lastElementIndex]\n",
    "out_array = array[1:]\n",
    "'''\n",
    "# Create flat list of Input and Output\n",
    "Input_flat=[]\n",
    "for sublist in In_array:\n",
    "    for element in sublist:\n",
    "        Input_flat.append(element)\n",
    "\n",
    "Output_flat=[]\n",
    "for sublist in Out_array:\n",
    "    for element in sublist:\n",
    "        Output_flat.append(element)\n",
    "\n",
    "\n",
    "# create output sequence for samples following input\n",
    "output = []\n",
    "for i in range(0, len(array)-1):\n",
    " i+=1\n",
    " #print(i)\n",
    " output.append(array[i])\n",
    "'''\n",
    "# output_stack = numpy.stack(out_array)\n",
    "\n",
    "# Get overall number of Input values from samples\n",
    "#Number_of_values = sum(x for x in sequence_length)\n",
    "\n",
    "\n",
    "# Create the Input and Output to tensors\n",
    "input_tensor = tf.convert_to_tensor(in_array)\n",
    "output_tensor = tf.convert_to_tensor(out_array)\n",
    "\n",
    "batch_size = len(input_tensor)\n",
    "timestep = sequence_length[0]\n",
    "\n",
    "input_data = tf.reshape(input_tensor, shape=(batch_size, timestep, 1))\n",
    "output_data = tf.reshape(output_tensor, shape=(batch_size, timestep, 1))\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(output_data)\n",
    "\n",
    "#Normalize the training data based on overall number of values\n",
    "#input_data = input_data / Number_of_values\n",
    "\n",
    "model = Sequential()\n",
    "first_lstm = LSTM(32,\n",
    "        batch_input_shape=(batch_size, timestep, 1),\n",
    "        return_sequences=True, activation='tanh',\n",
    "        stateful=True)\n",
    "\n",
    "model.add(first_lstm)\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#this is the last LSTM layer, use return_sequences=False\n",
    "model.add(LSTM(16, return_sequences=False, stateful=True,  activation='tanh'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.fit(input_data, output_data, epochs=2, batch_size=sequence_length[0], verbose=2)\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(LSTM(units= 1, batch_input_shape= [batch_size, timestep, 1], stateful=True, return_sequences=True))\n",
    "model.add(LSTM(units= 1, activation='relu', stateful=True, return_sequences=True, batch_input_shape=(batch_size, timestep, 1)))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.fit(input_data, output_data, epochs=5, batch_size=sequence_length[0], verbose=2)\n",
    "'''\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}