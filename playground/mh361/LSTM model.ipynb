{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 1791, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 66150, 1) and (9, 66150, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:87\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:69\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     67\u001B[0m   \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     68\u001B[0m   \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     71\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_h02mv14.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 1791, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 66150, 1) and (9, 66150, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import wave\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "import glob\n",
    "import os\n",
    "import Paths\n",
    "from pydub import AudioSegment\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, MaxPooling2D, Dropout, Activation\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "directory = os.listdir(Paths.IN_DIRECTORY)\n",
    "array = []\n",
    "\n",
    "sequence_length = []\n",
    "for sample_name in directory:\n",
    "    if 'wav' in sample_name:\n",
    "        file_path = os.path.join(Paths.IN_DIRECTORY, sample_name)\n",
    "        song, sr = librosa.load(file_path)\n",
    "        sequence_length.append(len(song))\n",
    "        #print(len(song))\n",
    "        #song = AudioSegment.from_wav(file_path)\n",
    "        #samples = song.get_array_of_samples()\n",
    "        array.append(song)\n",
    "\n",
    "# Removing the last element using slicing\n",
    "lastElementIndex = len(array)-1\n",
    "in_array = array[:lastElementIndex]\n",
    "out_array = array[1:]\n",
    "'''\n",
    "# Create flat list of Input and Output\n",
    "Input_flat=[]\n",
    "for sublist in In_array:\n",
    "    for element in sublist:\n",
    "        Input_flat.append(element)\n",
    "\n",
    "Output_flat=[]\n",
    "for sublist in Out_array:\n",
    "    for element in sublist:\n",
    "        Output_flat.append(element)\n",
    "\n",
    "\n",
    "# create output sequence for samples following input\n",
    "output = []\n",
    "for i in range(0, len(array)-1):\n",
    " i+=1\n",
    " #print(i)\n",
    " output.append(array[i])\n",
    "'''\n",
    "\n",
    "#Create the Input and Output to tensors\n",
    "input_tensor = tf.convert_to_tensor(in_array)\n",
    "output_tensor = tf.convert_to_tensor(out_array)\n",
    "\n",
    "\n",
    "batch_size = len(input_tensor)\n",
    "timestep = sequence_length[0]\n",
    "\n",
    "input_data = tf.reshape(input_tensor, shape=(batch_size, timestep, 1))\n",
    "output_data = tf.reshape(output_tensor, shape=(batch_size, timestep, 1))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units= 2, batch_input_shape= [9, 66150, 1], stateful=True, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(32, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(32))\n",
    "#model.add(Dense(32))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(n_vocab))\n",
    "#model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(input_data, output_data, epochs=200, batch_size=sequence_length[0], callbacks=callbacks_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 66150, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(input_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    " sequence_in = flatlist[i:i + sequence_length[i]]\n",
    "    sequence_out = flatlist[i + sequence_length[i]]\n",
    "    network_input.append(sequence_in)\n",
    "    network_output.append(sequence_out)\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# sequence_length = len(song)\n",
    "sequence_length = 100\n",
    "\n",
    "# get all pitch names\n",
    "pitchnames = sorted(set(item for item in flatlist))\n",
    "\n",
    "n_vocab = len(set(flatlist))\n",
    "\n",
    "# create a dictionary to map pitches to integers\n",
    "note_to_int = dict((flatlist, number) for number, flatlist in enumerate(pitchnames))\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(flatlist) - sequence_length, 1):\n",
    "    sequence_in = flatlist[i:i + sequence_length]\n",
    "    sequence_out = flatlist[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "# normalize input\n",
    "network_input = network_input / float(n_vocab)\n",
    "network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.00456181, 0.00744834, 0.00696913, ..., 0.03612468, 0.04514919,\n",
      "       0.        ], dtype=float32), array([0.04360344, 0.06247874, 0.05309957, ..., 0.12486256, 0.12134458,\n",
      "       0.1312821 ], dtype=float32), array([-0.01130085, -0.0170629 , -0.01534307, ..., -0.02985282,\n",
      "       -0.0294109 , -0.03418307], dtype=float32), array([0.07419518, 0.10791647, 0.0935066 , ..., 0.01373434, 0.01630254,\n",
      "       0.01927015], dtype=float32), array([-0.00057893, -0.00129468, -0.00135118, ..., -0.01974932,\n",
      "       -0.02698674,  0.        ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#print(network_input)\n",
    "print(array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' lstm_33/lstm_cell_33/kernel:0': Shape mismatch.The variable shape (1, 2048), and the assigned value shape (1, 1024) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [52]\u001B[0m, in \u001B[0;36m<cell line: 17>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrmsprop\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Load the weights to each node\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweights-improvement-59-2.5657-bigger.hdf5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:69\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     67\u001B[0m   \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     68\u001B[0m   \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     71\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\backend.py:4028\u001B[0m, in \u001B[0;36mbatch_set_value\u001B[1;34m(tuples)\u001B[0m\n\u001B[0;32m   4026\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m tf\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[0;32m   4027\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m x, value \u001B[38;5;129;01min\u001B[39;00m tuples:\n\u001B[1;32m-> 4028\u001B[0m     \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massign\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4029\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   4030\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m get_graph()\u001B[38;5;241m.\u001B[39mas_default():\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot assign value to variable ' lstm_33/lstm_cell_33/kernel:0': Shape mismatch.The variable shape (1, 2048), and the assigned value shape (1, 1024) are incompatible."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "# Load the weights to each node\n",
    "model.load_weights('weights-improvement-59-2.5657-bigger.hdf5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(network_input)-1)\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "pattern = network_input[start]\n",
    "prediction_output = []\n",
    "# generate 500 notes\n",
    "for note_index in range(500):\n",
    "    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_note[index]\n",
    "    prediction_output.append(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(1670, 1521)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pitchnames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mpitchnames\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pitchnames' is not defined"
     ]
    }
   ],
   "source": [
    "print(pitchnames)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}