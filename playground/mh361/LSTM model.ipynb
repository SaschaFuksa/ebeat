{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 1791, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 66150, 1) and (9, 66150, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:73\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:69\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     67\u001B[0m   \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     68\u001B[0m   \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     71\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filehe9zpno5.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 1791, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 66150, 1) and (9, 66150, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import wave\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "import glob\n",
    "import os\n",
    "import Paths\n",
    "from pydub import AudioSegment\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, MaxPooling2D, Dropout, Activation\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "directory = os.listdir(Paths.IN_DIRECTORY)\n",
    "array = []\n",
    "\n",
    "sequence_length = []\n",
    "for sample_name in directory:\n",
    "    if 'wav' in sample_name:\n",
    "        file_path = os.path.join(Paths.IN_DIRECTORY, sample_name)\n",
    "        song, sr = librosa.load(file_path)\n",
    "        sequence_length.append(len(song))\n",
    "        #print(len(song))\n",
    "        #song = AudioSegment.from_wav(file_path)\n",
    "        #samples = song.get_array_of_samples()\n",
    "        array.append(song)\n",
    "\n",
    "# Removing the last element using slicing\n",
    "lastElementIndex = len(array)-1\n",
    "in_array = array[:lastElementIndex]\n",
    "out_array = array[1:]\n",
    "'''\n",
    "# Create flat list of Input and Output\n",
    "Input_flat=[]\n",
    "for sublist in In_array:\n",
    "    for element in sublist:\n",
    "        Input_flat.append(element)\n",
    "\n",
    "Output_flat=[]\n",
    "for sublist in Out_array:\n",
    "    for element in sublist:\n",
    "        Output_flat.append(element)\n",
    "\n",
    "\n",
    "# create output sequence for samples following input\n",
    "output = []\n",
    "for i in range(0, len(array)-1):\n",
    " i+=1\n",
    " #print(i)\n",
    " output.append(array[i])\n",
    "'''\n",
    "# output_stack = numpy.stack(out_array)\n",
    "\n",
    "# Create the Input and Output to tensors\n",
    "input_tensor = tf.convert_to_tensor(in_array)\n",
    "output_tensor = tf.convert_to_tensor(out_array)\n",
    "\n",
    "# Creating a tf.Dataset for testing\n",
    "input_dataset = tf.data.Dataset.from_tensor_slices(in_array)\n",
    "output_dataset = tf.data.Dataset.from_tensor_slices(out_array)\n",
    "\n",
    "batch_size = len(input_tensor)\n",
    "timestep = sequence_length[0]\n",
    "\n",
    "input_data = tf.reshape(input_tensor, shape=(batch_size, timestep, 1))\n",
    "output_data = tf.reshape(output_tensor, shape=(batch_size, timestep, 1))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units= 3, batch_input_shape= [batch_size, timestep, 1], stateful=False, return_sequences=True))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.fit(input_data, output_data, epochs=200, batch_size=sequence_length[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(9, 66150, 1), dtype=float32, numpy=\narray([[[ 0.        ],\n        [ 0.        ],\n        [ 0.        ],\n        ...,\n        [-0.2871928 ],\n        [-0.27692395],\n        [-0.29513258]],\n\n       [[-0.19236994],\n        [-0.29156643],\n        [-0.25135237],\n        ...,\n        [-0.38337252],\n        [-0.36457327],\n        [-0.38309956]],\n\n       [[-0.20459306],\n        [-0.29983035],\n        [-0.2647556 ],\n        ...,\n        [-0.11268322],\n        [-0.11084475],\n        [-0.12078503]],\n\n       ...,\n\n       [[ 0.01349497],\n        [ 0.02101622],\n        [ 0.01949737],\n        ...,\n        [-0.01675961],\n        [-0.01825052],\n        [-0.02142336]],\n\n       [[-0.01493452],\n        [-0.02772336],\n        [-0.02656043],\n        ...,\n        [ 0.00588247],\n        [ 0.0055788 ],\n        [ 0.00640538]],\n\n       [[ 0.00332372],\n        [ 0.00353278],\n        [ 0.00265279],\n        ...,\n        [ 0.6077628 ],\n        [ 0.5598122 ],\n        [ 0.6999358 ]]], dtype=float32)>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 1791, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 66150, 1) and (9, 66150, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 22>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m ModelCheckpoint(\n\u001B[0;32m     15\u001B[0m     filepath, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     16\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m     17\u001B[0m     save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     18\u001B[0m     mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     19\u001B[0m )\n\u001B[0;32m     20\u001B[0m callbacks_list \u001B[38;5;241m=\u001B[39m [checkpoint]\n\u001B[1;32m---> 22\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msequence_length\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:69\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     67\u001B[0m   \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     68\u001B[0m   \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     71\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filehe9zpno5.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\losses.py\", line 1791, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\hennm\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 66150, 1) and (9, 66150, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units= 2, batch_input_shape= [9, 66150, 1], stateful=True, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(32, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(32))\n",
    "#model.add(Dense(32))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(n_vocab))\n",
    "#model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(input_data, input_data, epochs=200, batch_size=sequence_length[0], callbacks=callbacks_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 595350 values, but the requested shape has 1786050 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m input_data \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimestep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(input_data)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 595350 values, but the requested shape has 1786050 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "input_data = tf.reshape(input_tensor, shape=(batch_size, timestep, 3))\n",
    "print(input_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Backend \"sox\" is not one of available backends: ['soundfile'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[43mtorchaudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_audio_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msox\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# sox is the default\u001B[39;00m\n\u001B[0;32m      8\u001B[0m waveform, sample_rate \u001B[38;5;241m=\u001B[39m torchaudio\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:/Users/hennm/Dropbox/Studium/Master/Semester 2/Tec Lab/Music/Samples/Tea K Pea - nauticals_1.wav\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     10\u001B[0m downsample_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8000\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\torchaudio\\backend\\utils.py:44\u001B[0m, in \u001B[0;36mset_audio_backend\u001B[1;34m(backend)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;124;03m\"\"\"Set the backend for I/O operation\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \n\u001B[0;32m     38\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;124;03m        of the system. If ``None`` is provided the  current backend is unassigned.\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m backend \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m list_audio_backends():\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBackend \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not one of \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavailable backends: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlist_audio_backends()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     47\u001B[0m     module \u001B[38;5;241m=\u001B[39m no_backend\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Backend \"sox\" is not one of available backends: ['soundfile']."
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    " sequence_in = flatlist[i:i + sequence_length[i]]\n",
    "    sequence_out = flatlist[i + sequence_length[i]]\n",
    "    network_input.append(sequence_in)\n",
    "    network_output.append(sequence_out)\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# sequence_length = len(song)\n",
    "sequence_length = 100\n",
    "\n",
    "# get all pitch names\n",
    "pitchnames = sorted(set(item for item in flatlist))\n",
    "\n",
    "n_vocab = len(set(flatlist))\n",
    "\n",
    "# create a dictionary to map pitches to integers\n",
    "note_to_int = dict((flatlist, number) for number, flatlist in enumerate(pitchnames))\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(flatlist) - sequence_length, 1):\n",
    "    sequence_in = flatlist[i:i + sequence_length]\n",
    "    sequence_out = flatlist[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "# normalize input\n",
    "network_input = network_input / float(n_vocab)\n",
    "network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(network_input)\n",
    "print(array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "# Load the weights to each node\n",
    "model.load_weights('weights-improvement-59-2.5657-bigger.hdf5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = numpy.random.randint(0, len(network_input)-1)\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "pattern = network_input[start]\n",
    "prediction_output = []\n",
    "# generate 500 notes\n",
    "for note_index in range(500):\n",
    "    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_note[index]\n",
    "    prediction_output.append(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "\n",
    "torchaudio.set_audio_backend('sox')  # sox is the default\n",
    "\n",
    "waveform, sample_rate = torchaudio.load('C:/Users/hennm/Dropbox/Studium/Master/Semester 2/Tec Lab/Music/Samples/Tea K Pea - nauticals_1.wav')\n",
    "\n",
    "downsample_rate=8000\n",
    "\n",
    "downsample_resample = torchaudio.transforms.Resample(\n",
    "    sample_rate, downsample_rate, resampling_method='sinc_interpolation')\n",
    "\n",
    "down_sampled = downsample_resample(waveform)\n",
    "\n",
    "print(down_sampled)\n",
    "\n",
    "torchaudio.save(\n",
    "    'C:/Users/hennm/Dropbox/Studium/Master/Semester 2/Tec Lab/Music/Samples/temp.wav', torch.clamp(down_sampled, -1, 1), downsample_rate, precision=32)\n",
    "\n",
    "waveform2, sample_rate2 = torchaudio.load('temp.wav')\n",
    "\n",
    "print(waveform2)\n",
    "\n",
    "print((down_sampled - waveform2).abs().max())\n",
    "print((down_sampled - waveform2).abs().median())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(1670, 1521)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pitchnames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mpitchnames\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pitchnames' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}