{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tea K Pea - nauticals_1.wav', 'Tea K Pea - nauticals_2.wav', 'Tea K Pea - nauticals_3.wav', 'Tea K Pea - nauticals_4.wav', 'Tea K Pea - nauticals_5.wav', 'Tea K Pea - nauticals_6.wav', 'Tea K Pea - nauticals_7.wav', 'Tea K Pea - nauticals_8.wav', 'Tea K Pea - nauticals_9.wav', 'Tea K Pea - nauticals_10.wav']\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 50, 1)]           0         \n",
      "                                                                 \n",
      " RNN (LSTM)                  (None, 50, 64)            16896     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 50, 1)            65        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,961\n",
      "Trainable params: 16,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 64317136.0000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 64314240.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64313956.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64313564.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64312440.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64312156.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64311980.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64311824.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64311660.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64311504.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64311368.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64311224.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64311088.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64310940.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64310800.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64310648.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64310116.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64309476.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 64309328.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 64308144.0000\n",
      "Time Took :0.02 min\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\nmodel = Sequential()\\nmodel.add(LSTM(10, activation='relu', return_sequences=True, input_shape=(EDGE_SIZE, 1)))\\nmodel.add(Dense(1))\\nmodel.compile(optimizer='adam', loss='mse')\\n#model.summary()\\n\\n# fit model\\nmodel.fit(input_data, output_data, epochs=20000, verbose=1)\\n\""
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "import Paths\n",
    "from SampleModel import SampleModel\n",
    "from keras import models, layers\n",
    "import time\n",
    "\n",
    "directory = os.listdir(Paths.IN_DIRECTORY)\n",
    "\n",
    "EDGE_SIZE = 50\n",
    "\n",
    "\n",
    "def define_model(len_ts,\n",
    "                 hidden_neurons = 10,\n",
    "                 nfeature=1,\n",
    "                 batch_size=None,\n",
    "                 stateful=False):\n",
    "    in_out_neurons = 1\n",
    "\n",
    "    inp = layers.Input(batch_shape= (batch_size, len_ts, nfeature),\n",
    "                       name=\"input\")\n",
    "\n",
    "    rnn = layers.LSTM(hidden_neurons,\n",
    "                    return_sequences=True,\n",
    "                    stateful=stateful,\n",
    "                    name=\"RNN\")(inp)\n",
    "\n",
    "    dens = layers.TimeDistributed(layers.Dense(in_out_neurons,name=\"dense\"))(rnn)\n",
    "    model = models.Model(inputs=[inp],outputs=[dens])\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\",\n",
    "                  sample_weight_mode=\"temporal\",\n",
    "                  optimizer=\"rmsprop\")\n",
    "    return(model,(inp,rnn,dens))\n",
    "\n",
    "\n",
    "def load_sample_edges(path: str):\n",
    "    start_samples = []\n",
    "    end_samples = []\n",
    "    files = os.listdir(path)\n",
    "    files = sorted(files, key=lambda x: int(x.split('_')[-1].split(\".\")[0]))\n",
    "    print(files[:11])\n",
    "    i = 0\n",
    "    #sequence_length = []\n",
    "    sampleModel = []\n",
    "    for file_name in files:\n",
    "        if 'wav' in file_name:\n",
    "            complete_path = path + file_name\n",
    "            sample = AudioSegment.from_wav(complete_path)\n",
    "            sample_array = sample.get_array_of_samples()\n",
    "            start_array = sample_array[:EDGE_SIZE]\n",
    "            start_samples.append(start_array)\n",
    "            end_array = sample_array[-EDGE_SIZE:]\n",
    "            end_samples.append(end_array)\n",
    "            model = SampleModel(name=file_name, start=start_array, end=end_array)\n",
    "            sampleModel.append(model)\n",
    "            #sequence_length.append(len(model))\n",
    "            i += 1\n",
    "\n",
    "    end_samples = end_samples[:-1]\n",
    "    start_samples = start_samples[1:]\n",
    "\n",
    "    return end_samples, start_samples, sampleModel\n",
    "\n",
    "\n",
    "end_samples, start_samples, sampleModel = load_sample_edges(Paths.IN_DIRECTORY)\n",
    "\n",
    "\n",
    "\n",
    "source_samples = []\n",
    "target_samples = []\n",
    "source_values = set()\n",
    "target_values = set()\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < 9:\n",
    "    #print(end_samples[i])\n",
    "    #print(start_samples[i])\n",
    "    i += 1\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(end_samples):\n",
    "    source_samples.append(end_samples[i])\n",
    "    target_samples.append(start_samples[i])\n",
    "    for value in end_samples[i]:\n",
    "        if value not in source_values:\n",
    "            source_values.add(value)\n",
    "    for value in start_samples[i]:\n",
    "        if value not in target_values:\n",
    "            target_values.add(value)\n",
    "    i += 1\n",
    "\n",
    "source_values_sorted = sorted(list(source_values))\n",
    "target_values_sorted = sorted(list(target_values))\n",
    "\n",
    "#source_samples = tf.convert_to_tensor(source_samples)\n",
    "#target_samples = tf.convert_to_tensor(target_samples)\n",
    "\n",
    "input_data = tf.reshape(source_samples, shape=(len(source_samples), EDGE_SIZE, 1))\n",
    "output_data = tf.reshape(target_samples, shape=(len(source_samples), EDGE_SIZE, 1))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Removing the last element using slicing\n",
    "lastElementIndex = len(array)-1\n",
    "in_array = array[:lastElementIndex]\n",
    "out_array = array[1:]\n",
    "\n",
    "\n",
    "#Create the Input and Output to tensors\n",
    "input_tensor = tf.convert_to_tensor(in_array)\n",
    "output_tensor = tf.convert_to_tensor(out_array)\n",
    "\n",
    "\n",
    "\n",
    "timestep = sequence_length[0]\n",
    "\n",
    "input_data = tf.reshape(input_tensor, shape=(batch_size, timestep, 1))\n",
    "output_data = tf.reshape(output_tensor, shape=(batch_size, timestep, 1))\n",
    "\n",
    "\n",
    "\n",
    "# Test mit Conv1D Layer, MaxPooling1D Layer, Aktivierungsfunktion Sigmoid\n",
    "# MÃ¶gliche Anpassungen: Anzahl der Samples, Aktivierungsfunktion\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3,strides=1, padding=\"causal\", activation=\"sigmoid\",input_shape=[None, 1]))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=1, padding='same'))\n",
    "model.add(LSTM(100, activation='sigmoid', return_sequences=True, input_shape=(EDGE_SIZE, 1)))\n",
    "model.add(Dense(1))\n",
    "'''\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, activation='relu', return_sequences=True, input_shape=(EDGE_SIZE, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#model.summary()\n",
    "\n",
    "# fit model\n",
    "start = time.time()\n",
    "model.fit(input_data, output_data, epochs=20000, verbose=1)\n",
    "end = time.time()\n",
    "print(\"Time Took :{:3.2f} min\".format( (end-start)/60 ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - 138ms/epoch - 138ms/step\n",
      "[[[ 688.46576]\n",
      "  [ 839.8293 ]\n",
      "  [ 909.2725 ]\n",
      "  [ 937.69855]\n",
      "  [ 948.60583]\n",
      "  [ 952.67413]\n",
      "  [ 954.182  ]\n",
      "  [ 954.7379 ]\n",
      "  [ 954.94257]\n",
      "  [ 955.0178 ]\n",
      "  [ 955.0723 ]\n",
      "  [ 955.0825 ]\n",
      "  [ 955.1123 ]\n",
      "  [ 955.11365]\n",
      "  [ 955.11414]\n",
      "  [ 955.11444]\n",
      "  [ 955.1145 ]\n",
      "  [ 955.1145 ]\n",
      "  [ 955.1145 ]\n",
      "  [ 955.1145 ]\n",
      "  [ 955.1145 ]\n",
      "  [ 955.1087 ]\n",
      "  [ 955.1087 ]\n",
      "  [ 953.3539 ]\n",
      "  [ 953.19586]\n",
      "  [ 953.0825 ]\n",
      "  [ 953.0143 ]\n",
      "  [ 946.3453 ]\n",
      "  [ 916.7831 ]\n",
      "  [ 890.71765]\n",
      "  [ 874.0858 ]\n",
      "  [ 863.631  ]\n",
      "  [ 783.1165 ]\n",
      "  [ 643.125  ]\n",
      "  [ 372.41098]\n",
      "  [-232.65327]\n",
      "  [ 549.974  ]\n",
      "  [-342.99173]\n",
      "  [ 598.2129 ]\n",
      "  [-279.24628]\n",
      "  [ 603.42145]\n",
      "  [-248.40453]\n",
      "  [ 604.6853 ]\n",
      "  [-237.78093]\n",
      "  [ 604.6423 ]\n",
      "  [-236.81142]\n",
      "  [ 604.2097 ]\n",
      "  [-239.94588]\n",
      "  [ 603.7134 ]\n",
      "  [-325.84625]]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = source_samples[4]\n",
    "x_input = tf.reshape(x_input, (1, EDGE_SIZE, 1))\n",
    "yhat = model.predict(x_input, verbose=2)\n",
    "print(yhat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('h', [1653, -12, 1735, -115, 1678, -221, 1699, -255, 1841, -273, 1912, -393, 1860, -617, 1869, -848, 2021, -1057, 2138, -1300, 2103, -1568, 2060, -1759, 2148, -1845, 2231, -1933, 2131, -2083, 1954, -2222, 1913, -2303, 1961, -2419, 1881, -2636, 1690, -2839, 1614, -2889, 1670, -2830, 1618, -2795, 1388, -2788, 1195, -2717])\n"
     ]
    }
   ],
   "source": [
    "print(source_samples[5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(source_samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}