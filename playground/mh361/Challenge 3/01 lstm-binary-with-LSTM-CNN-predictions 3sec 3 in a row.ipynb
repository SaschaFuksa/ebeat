{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2052319e-e85d-4361-b060-52884246b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from pydub import AudioSegment\n",
    "from scipy import signal\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abb4ec0-273b-4150-bbfd-791ff14df2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathAudio = '/home/stud/m/mh361/share/sample-same/'\n",
    "files = librosa.util.find_files(pathAudio, ext=['mp3'])\n",
    "\n",
    "song_lounge_it = []\n",
    "song_tuesday_night = []\n",
    "song_kingtop = []\n",
    "for file in files:\n",
    "    if 'Maarten Schellekens - Lounge It' in file:\n",
    "        song_lounge_it.append(file)\n",
    "    if 'Maarten Schellekens - Tuesday Night Radio Edit' in file:\n",
    "        song_tuesday_night.append(file)\n",
    "    if 'Holizna' in file:\n",
    "        song_kingtop.append(file)\n",
    "song_lounge_it = sorted(song_lounge_it, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "song_tuesday_night = sorted(song_tuesday_night, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "song_kingtop = sorted(song_kingtop, key=lambda x: int(x.split('_')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b71c21",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_songs = []\n",
    "full_songs.extend(song_lounge_it)\n",
    "full_songs.extend(song_tuesday_night)\n",
    "full_songs.extend(song_kingtop)\n",
    "len(full_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef8cf4d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_sample(sample):\n",
    "    array_of_samples = sample.get_array_of_samples()\n",
    "    np_arr = np.array(array_of_samples)\n",
    "    np_arr = np_arr.reshape(1, -1)\n",
    "    return preprocessing.normalize(np_arr)\n",
    "\n",
    "\n",
    "samples = []\n",
    "samples_sec_canal = []\n",
    "for file_name in full_songs:\n",
    "    sample = AudioSegment.from_mp3(file_name)\n",
    "    mono_samples = sample.split_to_mono()\n",
    "    normalized_sample = normalize_sample(mono_samples[0])[0]\n",
    "    resampled_sample = signal.resample(normalized_sample, int(len(normalized_sample)/35))\n",
    "    samples.append(resampled_sample)\n",
    "    #normalized_sample_sec_canal = normalize_sample(mono_samples[1])[0]\n",
    "    #resampled_sample_sec_canal = signal.resample(normalized_sample_sec_canal, int(len(normalized_sample)/35))\n",
    "    #samples_sec_canal.append(resampled_sample_sec_canal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f77efb4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1431"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_size = min(map(len, samples))\n",
    "edge_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c8e94f-6997-49eb-91b7-c08285b1869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(len(samples)-2):\n",
    "    Y_train.append(True)\n",
    "    first_sample = list(samples[i][-edge_size:])\n",
    "    second_sample = list(samples[i + 1][:edge_size])\n",
    "    third_sample = list(samples[i + 2][:edge_size])\n",
    "    X_train.append(first_sample+second_sample+third_sample)\n",
    "    if(i < len(samples)-3):\n",
    "        Y_train.append(True)\n",
    "        sec_last_half = list(samples[i + 3][:edge_size])\n",
    "        X_train.append(first_sample+second_sample+sec_last_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be59877-d6a7-4eed-bd28-7069e010aa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1431"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(third_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e004b76-5aa3-493f-b6e4-35347d681fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "def get_strange_end_part(samples, current_index, max_len):\n",
    "    x = random.randint(max_len-1)\n",
    "    if (x != current_index+1) and (x != current_index+2):\n",
    "        return list(samples[x][:edge_size])\n",
    "    else:\n",
    "        return get_strange_end_part(samples, current_index, max_len)\n",
    "\n",
    "\n",
    "for i in range(len(samples)-2):\n",
    "    first_sample = list(samples[i][-edge_size:])\n",
    "    second_sample = get_strange_end_part(samples, i, len(samples))\n",
    "    third_sample = get_strange_end_part(samples, i+1, len(samples))\n",
    "    X_train.append(first_sample+second_sample+third_sample)\n",
    "    Y_train.append(False)\n",
    "    sec_last_half = get_strange_end_part(samples, i, len(samples))\n",
    "    X_train.append(first_sample+second_sample+sec_last_half)\n",
    "    Y_train.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef426dc4-fc40-4f9d-95a3-2273e035ce8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 4293)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape(-1, 3*edge_size)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38c41a0-a694-41d2-b07b-5885e910f076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d53431",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 19:12:48.745876: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-24 19:12:49.318716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9634 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:05:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 4292, 8)           24        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 2146, 8)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " cu_dnnlstm (CuDNNLSTM)      (None, 2146, 512)         1069056   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2146, 256)         131328    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 549376)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 549377    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,749,785\n",
      "Trainable params: 1,749,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, LSTM, Flatten, CuDNNLSTM, MaxPool1D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=1024, kernel_size=2, input_shape=(3*edge_size, 1))) # 2 # 3 / filters 512\n",
    "model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "model.add(CuDNNLSTM(512, return_sequences=True)) # 256 # 8 #512 #256\n",
    "model.add(Dense(256))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) #1 'rmsprop' 2 'adam' 3 SGD(learning_rate=0.01)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e324359e-4308-47ac-9af4-589a2eb41274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 19:12:51.507960: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 7605\n",
      "2022-06-24 19:12:51.509243: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-24 19:12:51.509892: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-24 19:12:51.509913: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-06-24 19:12:51.510320: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-24 19:12:51.510359: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 15s 137ms/step - loss: 2.0484 - accuracy: 0.4581\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.9106 - accuracy: 0.4948\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.8887 - accuracy: 0.4704\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 1.1012 - accuracy: 0.4854\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 0.8361 - accuracy: 0.4770\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 1.0200 - accuracy: 0.4807\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.8719 - accuracy: 0.5099\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.9174 - accuracy: 0.5024\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.8362 - accuracy: 0.5118\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.9983 - accuracy: 0.4939\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.8326 - accuracy: 0.4958\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.8271 - accuracy: 0.5165\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.8330 - accuracy: 0.5024\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.7950 - accuracy: 0.4770\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.8117 - accuracy: 0.4939\n",
      "Epoch 16/50\n",
      "41/67 [=================>............] - ETA: 2s - loss: 0.8069 - accuracy: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=50, batch_size=16) \n",
    "# batch size 8\n",
    "#3s 21ms/step - loss: 0.6818 - accuracy: 0.5719\n",
    "# 3s 21ms/step - loss: 0.7044 - accuracy: 0.5729\n",
    "# 3s 21ms/step - loss: 0.6933 - accuracy: 0.4747\n",
    "# 2s 17ms/step - loss: 0.6923 - accuracy: 0.5574\n",
    "# 3s 29ms/step - loss: 0.6837 - accuracy: 0.5667\n",
    "#121/121 [==============================] - 4s 30ms/step - loss: 0.6872 - accuracy: 0.5595 filters 512 , lstm 512\n",
    "\n",
    "#batch size 64\n",
    "# 2s 117ms/step - loss: 0.6428 - accuracy: 0.5957\n",
    "#16/16 [==============================] - 2s 114ms/step - loss: 0.6905 - accuracy: 0.5522 -> kernel 4 lstm 512\n",
    "# 16/16 [==============================] - 2s 115ms/step - loss: 0.6914 - accuracy: 0.5429 kernel 3 lstm 512\n",
    "# 16/16 [==============================] - 2s 134ms/step - loss: 0.6446 - accuracy: 0.6070 kernel 2 lstm 512 filters 512\n",
    "# Epoch 1000/1000\n",
    "# 16/16 [==============================] - 2s 131ms/step - loss: 0.5504 - accuracy: 0.6856\n",
    "\n",
    "#batch size 32\n",
    "#  1s 46ms/step - loss: 0.7023 - accuracy: 0.5553\n",
    "\n",
    "#batch size 128\n",
    "#1s 92ms/step - loss: 0.6887 - accuracy: 0.5346\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60baf3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_x_train = X_train[-5]\n",
    "example_x_train = example_x_train.reshape(1, 3*edge_size)\n",
    "model.predict(example_x_train) \n",
    "#array([[0.40588772]], dtype=float32)\n",
    "# array([[0.38362142]], dtype=float32)\n",
    "# array([[0.49879223]], dtype=float32)\n",
    "# array([[0.32653403]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661dafa-23ea-47f5-be12-eefcaff54f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_x_train = X_train[10]\n",
    "example_x_train = example_x_train.reshape(1, 3*edge_size)\n",
    "pred = model.predict(example_x_train) \n",
    "#array([[0.66257244]], dtype=float32)\n",
    "#array([[0.72944134]], dtype=float32)\n",
    "#array([[0.4988544]], dtype=float32)\n",
    "#array([[0.63189554]], dtype=float32)\n",
    "pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69345a92-6bb4-4086-a7d0-bebf82d25467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forschungsfragen\n",
    "#› Lässt sich ein „hörbarer“ Musikstream erzeugen?\n",
    "#› Reicht das stochastische Sampling? Wie lange ist eine optimale Sampledauer?\n",
    "#› Wie ähnlich müssen sich die Urspungstracks bezüglich Stimmung, Genre, etc sein?\n",
    "#› Müssen Metadaten wie Lautstärke, Tempo, Spektrum, etc mit einbezogen werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f39e97-c572-4339-97f5-701e9959d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_all_samples = '/home/stud/m/mh361/share/sample-pool/'\n",
    "sample_files = librosa.util.find_files(path_all_samples, ext=['mp3'])\n",
    "loaded_samples = {}\n",
    "for file_path in sample_files:\n",
    "    loaded_audio_file = AudioSegment.from_mp3(file_path)\n",
    "    sample_array = loaded_audio_file.get_array_of_samples()\n",
    "    resampled_part = signal.resample(sample_array, int(len(normalized_sample)/35))\n",
    "    if len(resampled_part) >= edge_size:\n",
    "        file_name = Path(file_path).stem\n",
    "        loaded_samples[file_name] = resampled_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b4855-a061-4e59-8b4d-d4bc108e7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(loaded_samples.keys())[1273][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba91d8c-7c9a-40cd-bb8f-662f0aa02e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sample_name = list(loaded_samples.keys())[1273]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0cc07-2196-4179-9381-fdf93c9dafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sample = loaded_samples[start_sample_name]\n",
    "reference_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5eb6d4-a97a-4313-8898-cd4bd2b12abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reference_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f95e43-3b90-4ae5-86c7-b0fb1f53a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Brylie Christopher Oxley - City view from Torni_119'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50250ee6-76c6-4a3c-83eb-9bbe9f29f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "max = 100\n",
    "selected_samples = [start_sample_name]\n",
    "song_counter = [start_sample_name, 0]\n",
    "song_blacklist = []\n",
    "while i < max:\n",
    "    best_sample_name = None\n",
    "    best_score = 0.00000\n",
    "    best_sample = []\n",
    "    for key, value in loaded_samples.items():\n",
    "        if (key not in selected_samples) and (key[:-4] not in song_blacklist):\n",
    "            ref_and_sample = np.append(reference_sample[-edge_size:], value[:edge_size])\n",
    "            prediction = model.predict(ref_and_sample.reshape(1, 932))\n",
    "            score = prediction[0][0]\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_sample_name = key\n",
    "                best_sample = value\n",
    "            if score > 0.99:\n",
    "                break\n",
    "    print('Predicted ' + best_sample_name + ' at position ' + str(i) + ' as best sample with score ' + str(\n",
    "        best_score))\n",
    "    reference_sample = best_sample\n",
    "    selected_samples.append(best_sample_name)\n",
    "    if song_counter[0] in best_sample_name:\n",
    "        song_counter[1] = song_counter[1]+1\n",
    "    else:\n",
    "        song_counter[0] = best_sample_name[:-4]\n",
    "        song_counter[1] = 0\n",
    "    if song_counter[1] >= 2:\n",
    "        song_blacklist.append(best_sample_name[:-4])\n",
    "    if len(song_blacklist) >= 3:\n",
    "        song_blacklist = song_blacklist[1:]\n",
    "    i += 1\n",
    "    #print(song_counter)\n",
    "    #if i > 1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafaf25d-d68b-47c0-b766-5742b46117b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "max = 100\n",
    "selected_samples = [start_sample_name]\n",
    "while i < max:\n",
    "    best_sample_name = None\n",
    "    best_score = 0.00000\n",
    "    best_sample = []\n",
    "    for key, value in loaded_samples.items():\n",
    "        if key not in selected_samples:\n",
    "            ref_and_sample = np.append(reference_sample[-edge_size:], value[:edge_size])\n",
    "            prediction = model.predict(ref_and_sample.reshape(1, 932))\n",
    "            score = prediction[0][0]\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_sample_name = key\n",
    "                best_sample = value\n",
    "            if score > 0.99:\n",
    "                break\n",
    "    print('Predicted ' + best_sample_name + ' at position ' + str(i) + ' as best sample with score ' + str(\n",
    "        best_score))\n",
    "    reference_sample = best_sample\n",
    "    selected_samples.append(best_sample_name)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59ecbb-ffed-44a0-b57a-8e266fee1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_song = AudioSegment.empty()\n",
    "for sample in selected_samples:\n",
    "    complete_path = '/home/stud/m/mh361/share/sample-pool/' + sample + '.mp3'\n",
    "    loaded_sample = AudioSegment.from_mp3(complete_path)\n",
    "    new_song += loaded_sample\n",
    "new_song.export('/home/stud/m/mh361/share/music-out/' + 'karacho_2.mp3', format='mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025862e-94bf-4767-b724-ad4034e85ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188acb6-4a84-432b-ba35-cbda658428a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
