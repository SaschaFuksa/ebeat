{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import Paths\n",
    "import librosa\n",
    "from scipy import signal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def play_wav(wav_file):\n",
    "    return ipythondisplay.Audio(wav_file)\n",
    "\n",
    "\n",
    "def test_batch_func_types(func, args):\n",
    "    ret = func(*args)\n",
    "    assert len(ret) == 2, \"[FAIL] get_batch must return two arguments (input and label)\"\n",
    "    assert type(ret[0]) == np.ndarray, \"[FAIL] test_batch_func_types: x is not np.array\"\n",
    "    assert type(ret[1]) == np.ndarray, \"[FAIL] test_batch_func_types: y is not np.array\"\n",
    "    print(\"[PASS] test_batch_func_types\")\n",
    "    return True\n",
    "\n",
    "def test_batch_func_shapes(func, args):\n",
    "    dataset, seq_length, batch_size = args\n",
    "    x, y = func(*args)\n",
    "    correct = (batch_size, seq_length)\n",
    "    assert x.shape == correct, \"[FAIL] test_batch_func_shapes: x {} is not correct shape {}\".format(x.shape, correct)\n",
    "    assert y.shape == correct, \"[FAIL] test_batch_func_shapes: y {} is not correct shape {}\".format(y.shape, correct)\n",
    "    print(\"[PASS] test_batch_func_shapes\")\n",
    "    return True\n",
    "\n",
    "def test_batch_func_next_step(func, args):\n",
    "    x, y = func(*args)\n",
    "    assert (x[:,1:] == y[:,:-1]).all(), \"[FAIL] test_batch_func_next_step: x_{t} must equal y_{t-1} for all t\"\n",
    "    print(\"[PASS] test_batch_func_next_step\")\n",
    "    return True\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 734 ms\n",
      "Wall time: 885 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "directory = os.listdir(Paths.IN_DIRECTORY)\n",
    "songs = []\n",
    "\n",
    "sequence_length = []\n",
    "for sample_name in directory:\n",
    "    if 'wav' in sample_name:\n",
    "        file_path = os.path.join(Paths.IN_DIRECTORY, sample_name)\n",
    "        song, sr = librosa.load(file_path)\n",
    "        resampled = signal.resample(song, 882)\n",
    "        sequence_length.append(len(song))\n",
    "        songs.append(resampled)\n",
    "\n",
    "\n",
    "vectorized_songs = np.concatenate( songs, axis=0 )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(songs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8820 unique characters in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Find all unique characters within the samples\n",
    "vocab = sorted(set(vectorized_songs))\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PASS] test_batch_func_types\n",
      "[PASS] test_batch_func_shapes\n",
      "[PASS] test_batch_func_next_step\n",
      "======\n",
      "[PASS] passed all tests!\n"
     ]
    }
   ],
   "source": [
    "def get_batch(vectorized_songs, seq_length, batch_size):\n",
    "  # the length of the vectorized songs string\n",
    "  n = vectorized_songs.shape[0] - 1\n",
    "  # randomly choose the starting indices for the examples in the training batch\n",
    "  idx = np.random.choice(n-seq_length, batch_size)\n",
    "\n",
    "  '''TODO: construct a list of input sequences for the training batch'''\n",
    "  input_batch = [vectorized_songs[i:i+seq_length] for i in idx]\n",
    "  '''TODO: construct a list of output sequences for the training batch'''\n",
    "  output_batch = [vectorized_songs[i+1: i+1+seq_length] for i in idx]\n",
    "\n",
    "  # x_batch, y_batch provide the true inputs and targets for network training\n",
    "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "  return x_batch, y_batch\n",
    "\n",
    "\n",
    "# Perform some simple tests to make sure your batch function is working properly!\n",
    "test_args = (vectorized_songs, 10, 2)\n",
    "if not test_batch_func_types(get_batch, test_args) or \\\n",
    "   not test_batch_func_shapes(get_batch, test_args) or \\\n",
    "   not test_batch_func_next_step(get_batch, test_args):\n",
    "   print(\"======\\n[FAIL] could not pass tests\")\n",
    "else:\n",
    "   print(\"======\\n[PASS] passed all tests!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def LSTM(rnn_units):\n",
    "  return tf.keras.layers.LSTM(\n",
    "    rnn_units,\n",
    "    return_sequences=True,\n",
    "    recurrent_initializer='glorot_uniform',\n",
    "    recurrent_activation='tanh',\n",
    "    stateful=True,\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    # Layer 1: Embedding layer to transform indices into dense vectors\n",
    "    #   of a fixed embedding size\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "\n",
    "    # Layer 2: LSTM with `rnn_units` number of units.\n",
    "    LSTM(rnn_units),\n",
    "\n",
    "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
    "    #   into the vocabulary size.\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "  ])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Build a simple model with default hyperparameters. You will get the\n",
    "#   chance to change these later.\n",
    "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (32, None, 256)           2257920   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (32, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (32, None, 8820)          9040500   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,545,396\n",
      "Trainable params: 16,545,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:       (32, 100)  # (batch_size, sequence_length)\n",
      "Prediction shape:  (32, 100, 8820) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5012, 7169, 2350, 4631,  315, 3724, 2642,  786, 8485, 5549, 2868,\n        477, 6857, 3332, 6540,  865, 3998, 2326,  654, 6848, 2651,  774,\n       5437,  990, 4598,  511, 5232, 1041, 2630, 3270,  771, 7007, 4577,\n       8233, 1833, 2470, 2759, 5267, 6168, 6042, 7046,  307, 7363,  137,\n        426, 7646, 7826, 8312,  470, 7769,  505, 2276, 4521, 5312, 8098,\n       1574, 4661, 7884, 6812, 1218, 8818, 2689, 8344, 5558, 7578, 7383,\n       8543,  313, 5748,  785, 4591,  141,   53, 5173, 4180, 6017, 2513,\n       8542, 2502, 1765, 4236, 2661, 6591, 8656, 1732, 7681, 7069, 4157,\n        860, 5012, 2157,  745, 6407, 6313, 3559, 4416, 8614, 1526, 7241,\n       6160], dtype=int64)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (32, 100, 8820)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       9.084778\n"
     ]
    }
   ],
   "source": [
    "'''TODO: define the loss function to compute and return the loss between\n",
    "    the true labels and predictions (logits). Set the argument from_logits=True.'''\n",
    "def compute_loss(labels, logits):\n",
    "  loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "  return loss\n",
    "\n",
    "'''TODO: compute the loss using the true next characters from the example batch\n",
    "    and the predictions from the untrained model several cells above'''\n",
    "example_batch_loss = compute_loss(y, pred)\n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Optimization parameters:\n",
    "num_training_iterations = 8  # Increase this to train longer\n",
    "batch_size = 4  # Experiment between 1 and 64\n",
    "seq_length = 100  # Experiment between 50 and 500\n",
    "learning_rate = 5e-3  # Experiment between 1e-5 and 1e-1\n",
    "\n",
    "# Model parameters:\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024  # Experiment between 1 and 2048\n",
    "\n",
    "# Checkpoint location:\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class PeriodicPlotter:\n",
    "  def __init__(self, sec, xlabel='', ylabel='', scale=None):\n",
    "\n",
    "    self.xlabel = xlabel\n",
    "    self.ylabel = ylabel\n",
    "    self.sec = sec\n",
    "    self.scale = scale\n",
    "\n",
    "    self.tic = time.time()\n",
    "\n",
    "  def plot(self, data):\n",
    "    if time.time() - self.tic > self.sec:\n",
    "      plt.cla()\n",
    "\n",
    "      if self.scale is None:\n",
    "        plt.plot(data)\n",
    "      elif self.scale == 'semilogx':\n",
    "        plt.semilogx(data)\n",
    "      elif self.scale == 'semilogy':\n",
    "        plt.semilogy(data)\n",
    "      elif self.scale == 'loglog':\n",
    "        plt.loglog(data)\n",
    "      else:\n",
    "        raise ValueError(\"unrecognized parameter scale {}\".format(self.scale))\n",
    "\n",
    "      plt.xlabel(self.xlabel); plt.ylabel(self.ylabel)\n",
    "      ipythondisplay.clear_output(wait=True)\n",
    "      ipythondisplay.display(plt.gcf())\n",
    "\n",
    "      self.tic = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:10<00:00,  1.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' instantiate a new model for training using the `build_model`\n",
    "  function and use hyperparameters above.'''\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "'''TODO: instantiate an optimizer with its learning rate.'''\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "  # Use tf.GradientTape()\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    '''TODO: feed the current input into the model and generate predictions'''\n",
    "    y_hat = model(x)\n",
    "\n",
    "    '''TODO: compute the loss!'''\n",
    "    loss = compute_loss(y, y_hat)\n",
    "\n",
    "  # Now, compute the gradients\n",
    "  '''TODO: complete the function call for gradient computation.\n",
    "      Remember that we want the gradient of the loss with respect all\n",
    "      of the model parameters.\n",
    "      HINT: use `model.trainable_variables` to get a list of all model\n",
    "      parameters.'''\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "  # Apply the gradients to the optimizer so it can update the model accordingly\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "  return loss\n",
    "\n",
    "# Begin training\n",
    "\n",
    "history = []\n",
    "plotter = PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "\n",
    "  # Grab a batch and propagate it through the network\n",
    "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
    "  loss = train_step(x_batch, y_batch)\n",
    "\n",
    "  # Update the progress bar\n",
    "  history.append(loss.numpy().mean())\n",
    "  plotter.plot(history)\n",
    "\n",
    "  # Update the model with the changed weights!\n",
    "  if iter % 100 == 0:\n",
    "    model.save_weights(checkpoint_prefix)\n",
    "\n",
    "# Save the trained model and the weights\n",
    "model.save_weights(checkpoint_prefix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def generate_prediction(model, start_value, generation_length):\n",
    "\n",
    "  '''TODO: Get the start_value which is used for prediction'''\n",
    "  input_eval = start_value\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  print(input_eval)\n",
    "\n",
    "  # Empty list to store our results\n",
    "  generated = []\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  tqdm._instances.clear()\n",
    "\n",
    "  for i in tqdm(range(generation_length)):\n",
    "      predictions = model(input_eval)\n",
    "\n",
    "      # Remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      '''TODO: use a multinomial distribution to sample'''\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # Pass the prediction along with the previous hidden state\n",
    "      #   as the next inputs to the model\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      '''TODO: add the predicted character to the generated text!'''\n",
    "      # Hint: consider what format the prediction is in vs. the output\n",
    "      generated.append(vocab[predicted_id])\n",
    "\n",
    "  return (start_value + ''.join(generated))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([20], shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_1\" (type Sequential).\n\nInput 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1, 256)\n\nCall arguments received by layer \"sequential_1\" (type Sequential):\n  • inputs=tf.Tensor(shape=(1,), dtype=int32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [42]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m'''TODO: Use the model and the function defined above to generate ABC format text of length 1000!\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m generate_prediction \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgeneration_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [41]\u001B[0m, in \u001B[0;36mgenerate_prediction\u001B[1;34m(model, start_value, generation_length)\u001B[0m\n\u001B[0;32m     13\u001B[0m tqdm\u001B[38;5;241m.\u001B[39m_instances\u001B[38;5;241m.\u001B[39mclear()\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(generation_length)):\n\u001B[1;32m---> 16\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;66;03m# Remove the batch dimension\u001B[39;00m\n\u001B[0;32m     19\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39msqueeze(predictions, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:69\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     67\u001B[0m   \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     68\u001B[0m   \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     71\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\ebeat\\venv\\lib\\site-packages\\keras\\engine\\input_spec.py:214\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[1;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[0;32m    212\u001B[0m   ndim \u001B[38;5;241m=\u001B[39m shape\u001B[38;5;241m.\u001B[39mrank\n\u001B[0;32m    213\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;241m!=\u001B[39m spec\u001B[38;5;241m.\u001B[39mndim:\n\u001B[1;32m--> 214\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    215\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis incompatible with the layer: \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    216\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexpected ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, found ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    217\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFull shape received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(shape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mmax_ndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    219\u001B[0m   ndim \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n\nInput 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1, 256)\n\nCall arguments received by layer \"sequential_1\" (type Sequential):\n  • inputs=tf.Tensor(shape=(1,), dtype=int32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "'''TODO: Predict values based on start value'''\n",
    "generate_prediction = generate_prediction(model, start_value=20, generation_length=1000) # TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}